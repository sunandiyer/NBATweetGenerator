{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filename = \"wonderland.txt\"\n",
    "#raw_text = open(filename).read()\n",
    "#raw_text = raw_text.lower()\n",
    "\n",
    "\n",
    "consumer_key = \"1vnx8rybX0CvnERfLOfZRkJmN\"\n",
    "consumer_secret = 'pYSzrmJqlLT3A8znLBpSzt3djC0NwGAIDctLeJevHOIX9KBlfM'\n",
    "access_token = '1478601054-yjTbHT3FJdLCleRbZnnmFcsqkIroSKeKqZROCPw'\n",
    "access_secret = 'cHKGTKWcEds0q6FjdwJPV01qt6L2bhvFTuQAxWtdDHHFj'\n",
    "        \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "tweets = \"\"\n",
    "for i in range(5):\n",
    "    new_tweets = api.user_timeline(screen_name = 'wojespn',count=200)\n",
    "    for tweet in new_tweets:\n",
    "        tweets += re.sub(r'http\\S+', '', tweet.text)\n",
    "        tweets += \"\\n\"\n",
    "raw_text = tweets.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '’', '…', '\\u2066', '\\u2069']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101460"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outFile = open(\"corpus.txt\", \"w\")\n",
    "outFile.write(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inFile = open(\"corpus.txt\", \"r\")\n",
    "lines = [line for line in inFile.readlines()]\n",
    "#print(lines)\n",
    "raw_text = \"\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  101460\n",
      "Total Vocab:  58\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  101385\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 75\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101385, 75, 1)\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "print(X.shape)\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, input_shape=(256,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 3.0907Epoch 00001: loss improved from inf to 3.09061, saving model to weights-improvement-01-3.0906.hdf5\n",
      "101385/101385 [==============================] - 583s 6ms/step - loss: 3.0906\n",
      "Epoch 2/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 2.8246Epoch 00002: loss improved from 3.09061 to 2.82454, saving model to weights-improvement-02-2.8245.hdf5\n",
      "101385/101385 [==============================] - 580s 6ms/step - loss: 2.8245\n",
      "Epoch 3/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 2.5288Epoch 00003: loss improved from 2.82454 to 2.52875, saving model to weights-improvement-03-2.5287.hdf5\n",
      "101385/101385 [==============================] - 580s 6ms/step - loss: 2.5287\n",
      "Epoch 4/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 2.2967Epoch 00004: loss improved from 2.52875 to 2.29667, saving model to weights-improvement-04-2.2967.hdf5\n",
      "101385/101385 [==============================] - 579s 6ms/step - loss: 2.2967\n",
      "Epoch 5/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 2.0849Epoch 00005: loss improved from 2.29667 to 2.08487, saving model to weights-improvement-05-2.0849.hdf5\n",
      "101385/101385 [==============================] - 581s 6ms/step - loss: 2.0849\n",
      "Epoch 6/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 1.8858Epoch 00006: loss improved from 2.08487 to 1.88573, saving model to weights-improvement-06-1.8857.hdf5\n",
      "101385/101385 [==============================] - 581s 6ms/step - loss: 1.8857\n",
      "Epoch 7/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 1.6919Epoch 00007: loss improved from 1.88573 to 1.69194, saving model to weights-improvement-07-1.6919.hdf5\n",
      "101385/101385 [==============================] - 582s 6ms/step - loss: 1.6919\n",
      "Epoch 8/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 1.5127Epoch 00008: loss improved from 1.69194 to 1.51275, saving model to weights-improvement-08-1.5127.hdf5\n",
      "101385/101385 [==============================] - 581s 6ms/step - loss: 1.5127\n",
      "Epoch 9/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 1.3557Epoch 00009: loss improved from 1.51275 to 1.35566, saving model to weights-improvement-09-1.3557.hdf5\n",
      "101385/101385 [==============================] - 580s 6ms/step - loss: 1.3557\n",
      "Epoch 10/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 1.2096Epoch 00010: loss improved from 1.35566 to 1.20955, saving model to weights-improvement-10-1.2095.hdf5\n",
      "101385/101385 [==============================] - 622s 6ms/step - loss: 1.2095\n",
      "Epoch 11/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 1.0837Epoch 00011: loss improved from 1.20955 to 1.08367, saving model to weights-improvement-11-1.0837.hdf5\n",
      "101385/101385 [==============================] - 588s 6ms/step - loss: 1.0837\n",
      "Epoch 12/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.9708Epoch 00012: loss improved from 1.08367 to 0.97077, saving model to weights-improvement-12-0.9708.hdf5\n",
      "101385/101385 [==============================] - 588s 6ms/step - loss: 0.9708\n",
      "Epoch 13/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.8691Epoch 00013: loss improved from 0.97077 to 0.86902, saving model to weights-improvement-13-0.8690.hdf5\n",
      "101385/101385 [==============================] - 646s 6ms/step - loss: 0.8690\n",
      "Epoch 14/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.7897Epoch 00014: loss improved from 0.86902 to 0.78967, saving model to weights-improvement-14-0.7897.hdf5\n",
      "101385/101385 [==============================] - 640s 6ms/step - loss: 0.7897\n",
      "Epoch 15/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.7166Epoch 00015: loss improved from 0.78967 to 0.71657, saving model to weights-improvement-15-0.7166.hdf5\n",
      "101385/101385 [==============================] - 659s 6ms/step - loss: 0.7166\n",
      "Epoch 16/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.6517Epoch 00016: loss improved from 0.71657 to 0.65164, saving model to weights-improvement-16-0.6516.hdf5\n",
      "101385/101385 [==============================] - 696s 7ms/step - loss: 0.6516\n",
      "Epoch 17/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.5980Epoch 00017: loss improved from 0.65164 to 0.59804, saving model to weights-improvement-17-0.5980.hdf5\n",
      "101385/101385 [==============================] - 617s 6ms/step - loss: 0.5980\n",
      "Epoch 18/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.6355Epoch 00018: loss did not improve\n",
      "101385/101385 [==============================] - 719s 7ms/step - loss: 0.6354\n",
      "Epoch 19/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.4985Epoch 00019: loss improved from 0.59804 to 0.49847, saving model to weights-improvement-19-0.4985.hdf5\n",
      "101385/101385 [==============================] - 624s 6ms/step - loss: 0.4985\n",
      "Epoch 20/20\n",
      "101376/101385 [============================>.] - ETA: 0s - loss: 0.4724Epoch 00020: loss improved from 0.49847 to 0.47237, saving model to weights-improvement-20-0.4724.hdf5\n",
      "101385/101385 [==============================] - 589s 6ms/step - loss: 0.4724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1421190b8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-20-0.4724.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a5b1e83cd027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 39, 39, 1, 30, 42, 41, 46, 36, 31, 32, 45, 1, 48, 43, 42, 41, 1, 30, 39, 32, 28, 45, 36, 41, 34, 1, 50, 28, 36, 49, 32, 45, 46, 9, 1, 39, 32, 28, 34, 48, 32, 1, 46, 42, 48, 55, 1, 0, 37, 28, 53, 53, 1, 50, 28, 36, 49, 32, 31, 1, 37, 42, 41, 28, 46, 1, 37, 32, 45, 32, 29, 38, 42, 11]\n",
      "Seed:\n",
      "\" ill consider upon clearing waivers, league sou… \n",
      "jazz waived jonas jerebko. \"\n",
      "end seed\n",
      "\n",
      "espn story on fusuf uurki cgreec to a two-year, $12m deal. \n",
      "free agent guard tyreke evans is nearing a one-year deal with the indiana pacer\n",
      "Done.\n",
      "[39, 42, 47, 47, 32, 9, 1, 39, 32, 28, 34, 48, 32, 1, 46, 42, 48, 45, 30, 32, 1, 47, 32, 39, 39, 46, 1, 32, 46, 43, 41, 0, 32, 46, 43, 41, 1, 46, 42, 48, 45, 30, 32, 46, 1, 50, 36, 47, 35, 1, 26, 45, 42, 52, 30, 32, 52, 42, 48, 41, 34, 23, 1, 42, 38, 39, 28, 35, 42, 40, 28, 1, 30, 36, 47]\n",
      "Seed:\n",
      "\" lotte, league source tells espn\n",
      "espn sources with @royceyoung: oklahoma cit \"\n",
      "end seed\n",
      "y, carmelo anthony will part ways thes wime makens and tas beree boronty'y frens toeet to $33m \n",
      "an iaclen and tuaye centle to aiton touat fr\n",
      "Done.\n",
      "[1, 33, 45, 32, 32, 1, 28, 34, 32, 41, 47, 1, 30, 32, 41, 47, 32, 45, 1, 30, 39, 36, 41, 47, 1, 30, 28, 43, 32, 39, 28, 1, 28, 41, 31, 1, 35, 36, 46, 1, 50, 28, 46, 46, 32, 45, 40, 28, 41, 1, 40, 32, 31, 36, 28, 1, 34, 45, 42, 48, 43, 1, 28, 34, 32, 41, 47, 46, 55, 1, 0, 45, 47, 1, 26]\n",
      "Seed:\n",
      "\"  free agent center clint capela and his wasserman media group agents… \n",
      "rt @ \"\n",
      "end seed\n",
      "marcjspearsespn: new orleans pelicans all-star free agent center demarcus cousins retein ficks and hulyre the lolcane pelars hor hr a deat  \n",
      "Done.\n",
      "[32, 45, 32, 54, 46, 1, 36, 41, 47, 55, 1, 0, 32, 46, 43, 41, 1, 46, 47, 42, 45, 52, 1, 42, 41, 1, 33, 45, 32, 32, 1, 28, 34, 32, 41, 47, 1, 34, 48, 28, 45, 31, 1, 46, 32, 47, 35, 1, 30, 48, 45, 45, 52, 1, 37, 42, 36, 41, 36, 41, 34, 1, 47, 35, 32, 1, 29, 39, 28, 53, 32, 45, 46, 11, 1]\n",
      "Seed:\n",
      "\" ere’s int… \n",
      "espn story on free agent guard seth curry joining the blazers.  \"\n",
      "end seed\n",
      "\n",
      "espn story on all-star center denarcus cousins agreeing on a one-year, $123m deal with the golden state warriors. \n",
      "so gm bob myers has repl\n",
      "Done.\n",
      "[1, 41, 42, 29, 42, 31, 52, 25, 1, 31, 36, 31, 1, 35, 32, 1, 46, 47, 28, 52, 1, 42, 41, 1, 47, 35, 32, 1, 50, 32, 46, 47, 1, 30, 42, 28, 46, 47, 25, 0, 46, 42, 48, 45, 30, 32, 46, 1, 42, 41, 1, 32, 46, 43, 41, 23, 1, 42, 38, 39, 28, 35, 42, 40, 28, 1, 30, 36, 47, 52, 1, 47, 35, 48, 41]\n",
      "Seed:\n",
      "\"  nobody? did he stay on the west coast?\n",
      "sources on espn: oklahoma city thun \"\n",
      "end seed\n",
      "der star paul george informs ara hesting toan iiclirs hav clecdas to a two-year, $12m deal  \n",
      "free agent guard tyreke evans is nearing a one-\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# pick a random seed\n",
    "for i in range(5):\n",
    "    start = numpy.random.randint(0, len(dataX)-1)\n",
    "    pattern = dataX[start]\n",
    "    print(pattern)\n",
    "    print(\"Seed:\")\n",
    "    print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "    print(\"end seed\")\n",
    "    # generate characters\n",
    "    for i in range(140):\n",
    "        count = 0\n",
    "        x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = x / float(n_vocab)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_char[index]\n",
    "        \n",
    "        #if result == \"\\n\":\n",
    "            \n",
    "        #    break\n",
    "         \n",
    "        seq_in = [int_to_char[value] for value in pattern]\n",
    "        sys.stdout.write(result)\n",
    "        pattern.append(index)\n",
    "\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
